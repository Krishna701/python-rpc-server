{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mind_test = pd.read_csv(\"news.tsv\", header = None, sep = \"\\t\")\n",
    "mind_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mind_test.columns = ['news_id',\n",
    "                    \"category\",\n",
    "                    \"sub_category\",\n",
    "                    \"title\",\n",
    "                    \"abstract\",\n",
    "                    \"url\",\n",
    "                    \"title_entities\",\n",
    "                    \"abstract_entities \"]\n",
    "mind_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mind_test = mind_test[['news_id',\n",
    "                    \"category\",\n",
    "                    \"sub_category\",\n",
    "                    \"title\",\n",
    "                    \"abstract\"\n",
    "                    ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the number of articles before processing Title :',len(mind_test))\n",
    "mind_test.drop_duplicates(subset=['title'],inplace=True)\n",
    "print('The number of articles after processing Title:',len(mind_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the number of articles before processing Abstract:',len(mind_test))\n",
    "mind_test.drop_duplicates(subset=['abstract'],inplace=True)\n",
    "print('The number of articles after processing Abstract:',len(mind_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mind_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mind_test.to_csv(\"Test.csv\")\n",
    "mind_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import tez\n",
    "# from sklearn import model_selection\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from sklearn import metrics, preprocessing\n",
    "\n",
    "# class NewsDatasets:\n",
    "#     def __init__(self, users_id, titles,publications, authors, contents, ratings):\n",
    "#         self.users_id = users_id\n",
    "#         self.title = titles\n",
    "#         self.publication = publications\n",
    "#         self.author = authors\n",
    "#         self.content = contents\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.users_id)\n",
    "\n",
    "\n",
    "#     def __getitem__(self, item):\n",
    "#         user = self.users_id[item]\n",
    "#         title = self.titles[item]\n",
    "#         publication = self.publications[item]\n",
    "#         author = self.authors[item]\n",
    "#         content = self.contents[item]\n",
    "\n",
    "#         return {\n",
    "#             'users_id': torch.tensor(user, dtype=torch.long),\n",
    "#             'titles': torch.tensor(title, dtype=torch.long),\n",
    "#             'publications': torch.tensor(publication, dtype=torch.float),\n",
    "#             'authors': torch.tensor(author, dtype=torch.float),\n",
    "#             'contents': torch.tensor(content, dtype=torch.float)\n",
    "#             }\n",
    "\n",
    "\n",
    "# class RecSysModel(tez.Model):\n",
    "#     def __init__(self,num_users, num_titles, num_publications, num_authors, num_contents):\n",
    "#         super().__init__()\n",
    "#         self.user_embed = nn.Embedding(num_users, 32)\n",
    "#         self.title_embed = nn.Embedding(num_titles, 32)\n",
    "#         self.publication_embed = nn.Embedding(num_publications, 32)\n",
    "#         self.author_embed = nn.Embedding(num_authors, 32)\n",
    "#         self.content_embed = nn.Embedding(num_contents, 32)\n",
    "\n",
    "#         self.out = nn.Linear(64,1)\n",
    "#         self.step_scheduler_after = 'epoch'\n",
    "\n",
    "\n",
    "#     def fetch_optimizer(self):\n",
    "#         opt = torch.optim.Adam(self.parameters(), lr = 1e-5)\n",
    "#         return opt\n",
    "    \n",
    "#     def fetch_scheduler(self):\n",
    "#         sch = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size = 3, gamma = 0.7)\n",
    "#         return sch\n",
    "\n",
    "#     def monitor_metrics(self, output, rating):\n",
    "#         output = output.detach().cpu().numpy()\n",
    "#         rating = rating.detach().cpu().numpy()\n",
    "#         return {\n",
    "#                 'rmse': np.sqrt(metrics.mean_squared_error(rating,output))\n",
    "#         }\n",
    "\n",
    "#     def forward(self, users_id, titles, publications, author, content, ratings =None ):\n",
    "#         user_embeds = self.user_embed(users_id)\n",
    "#         title_embeds = self.title_embed(titles)\n",
    "#         publication_embeds = self.publication_embed(publications)\n",
    "#         author_embeds = self.author_embed(author)\n",
    "#         content_embeds = self.content_embed(content)\n",
    "\n",
    "#         output = torch.cat([user_embeds, title_embeds, publication_embeds, author_embeds, content_embeds], dim = 1)\n",
    "#         output = self.out(output)\n",
    "        \n",
    "#         if ratings:\n",
    "#             loss = nn.MSELoss()(output, ratings.view(-1,1))\n",
    "#             calc_metrics = self.monitor_metrics(output,ratings.view(-1,1))\n",
    "#             return output, loss, calc_metrics\n",
    "# def train():\n",
    "#     df = pd.read_csv(\"Test.csv\")\n",
    "#     lbl_userid = preprocessing.LabelEncoder()\n",
    "#     lbl_titles = preprocessing.LabelEncoder()\n",
    "#     lbl_publications = preprocessing.LabelEncoder()\n",
    "#     lbl_authors = preprocessing.LabelEncoder()\n",
    "#     lbl_content = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "#     df.user = lbl_userid.fit_transform(df.user.values)\n",
    "#     df.title = lbl_titles.fit_transform(df.title.values)\n",
    "#     df.publications = lbl_publications.fit_transform(df.publication.values)\n",
    "#     df.author = lbl_authors.fit_transform(df.author.values)\n",
    "#     df.content = lbl_content.fit_transform(df.content.values)\n",
    "\n",
    "\n",
    "    \n",
    "#     df_train, df_valid = model_selection.train_test_split(\n",
    "#         df, test_size=0.3,random_state=42, stratify = df.rating.values\n",
    "#     )\n",
    "#     train_dataset = NewsDatasets(\n",
    "#         # df_train.user.values,df_train.movies.values,df_train.ratings.values\n",
    "#         df_train.user.values,df_valid.titles.values, df_valid.productions.values, df_valid.authors.values, df_valid.contents.values, df_valid.ratings.values\n",
    "#     )\n",
    "    \n",
    "#     valid_dataset = NewsDatasets(\n",
    "#         df_train.user.values,df_valid.titles.values, df_valid.productions.values, df_valid.authors.values, df_valid.contents.values, df_valid.ratings.values\n",
    "#     )\n",
    "#     model = RecSysModel(num_users = len(lbl_userid.classes_), \n",
    "#                         num_titles=len(lbl_titles.classes_), \n",
    "#                         num_productions=len(lbl_publications.classes_),\n",
    "#                         num_authors=len(lbl_authors.classes_),\n",
    "#                         num_contents=len(lbl_content.classes_)\n",
    "#                         )\n",
    "#     model.fit(\n",
    "#         train_dataset, valid_dataset, train_bs= 1024, valid_bs = 1024, fp16 = True\n",
    "#     )\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# print(torch.__version__)\n",
    "# my_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32, device=\"cpu\")\n",
    "# print(my_tensor)\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tez\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn import metrics, preprocessing\n",
    "\n",
    "class NewsDatasets:\n",
    "    def __init__(self, news_id, title,category, abstract, sub_category):\n",
    "        self.news_id = news_id\n",
    "        self.title = title\n",
    "        self.category = category\n",
    "        self.abstract = abstract\n",
    "        self.sub_category = sub_category\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.news_id)\n",
    "\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        news = self.news_id[item]\n",
    "        title = self.title[item]\n",
    "        category = self.category[item]\n",
    "        abstract = self.abstract[item]\n",
    "        sub_category = self.sub_category[item]\n",
    "\n",
    "        return {\n",
    "            'news_id': torch.tensor(news, dtype=torch.long),\n",
    "            'title': torch.tensor(title, dtype=torch.long),\n",
    "            'category': torch.tensor(category, dtype=torch.float),\n",
    "            'abstract': torch.tensor(abstract, dtype=torch.float),\n",
    "            'sub_category': torch.tensor(sub_category, dtype=torch.float)\n",
    "            }\n",
    "\n",
    "\n",
    "class RecSysModel(tez.Model):\n",
    "    def __init__(self,num_news, num_title, num_category, num_abstract, num_sub_category):\n",
    "        super().__init__()\n",
    "        self.news_embed = nn.Embedding(num_news, 32)\n",
    "        self.title_embed = nn.Embedding(num_title, 32)\n",
    "        self.category_embed = nn.Embedding(num_category, 32)\n",
    "        self.abstract_embed = nn.Embedding(num_abstract, 32)\n",
    "        self.sub_category_embed = nn.Embedding(num_sub_category, 32)\n",
    "\n",
    "        self.out = nn.Linear(64,1)\n",
    "        self.step_scheduler_after = 'epoch'\n",
    "\n",
    "\n",
    "    def fetch_optimizer(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr = 1e-5)\n",
    "        return opt\n",
    "    \n",
    "    def fetch_scheduler(self):\n",
    "        sch = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size = 3, gamma = 0.7)\n",
    "        return sch\n",
    "\n",
    "    # def monitor_metrics(self, output, rating):\n",
    "    #     output = output.detach().cpu().numpy()\n",
    "    #     rating = rating.detach().cpu().numpy()\n",
    "    #     return {\n",
    "    #             'rmse': np.sqrt(metrics.mean_squared_error(rating,output))\n",
    "    #     }\n",
    "\n",
    "    def forward(self, news_id, title, category, abstract, sub_category ):\n",
    "        news_embeds = self.news_embed(news_id)\n",
    "        title_embeds = self.title_embed(title)\n",
    "        category_embeds = self.category_embed(category)\n",
    "        abstract_embeds = self.abstract_embed(abstract)\n",
    "        sub_category_embeds = self.sub_category_embed(sub_category)\n",
    "\n",
    "        output = torch.cat([news_embeds, title_embeds, category_embeds, abstract_embeds, sub_category_embeds], dim = 1)\n",
    "        output = self.out(output)\n",
    "        \n",
    "        # if ratings:\n",
    "        #     loss = nn.MSELoss()(output, ratings.view(-1,1))\n",
    "        #     calc_metrics = self.monitor_metrics(output,ratings.view(-1,1))\n",
    "        #     return output, loss, calc_metrics\n",
    "def train():\n",
    "    df = pd.read_csv(\"Test.csv\")\n",
    "    lbl_news_id = preprocessing.LabelEncoder()\n",
    "    lbl_title = preprocessing.LabelEncoder()\n",
    "    lbl_category = preprocessing.LabelEncoder()\n",
    "    lbl_abstract = preprocessing.LabelEncoder()\n",
    "    lbl_sub_category = preprocessing.LabelEncoder()\n",
    "\n",
    "    print(df.columns)\n",
    "\n",
    "    df.news_id = lbl_news_id.fit_transform(df.news_id.values)\n",
    "    df.title = lbl_title.fit_transform(df.title.values)\n",
    "    df.category = lbl_category.fit_transform(df.category.values)\n",
    "    df.abstract = lbl_abstract.fit_transform(df.abstract.values)\n",
    "    df.sub_category = lbl_sub_category.fit_transform(df.sub_category.values)\n",
    "\n",
    "    print(df.shape)\n",
    "    \n",
    "    df_train, df_valid = model_selection.train_test_split(\n",
    "        # df, test_size=0.3,random_state=42, stratify = df.rating.values\n",
    "        df, test_size=0.3,random_state=42\n",
    "    )\n",
    "    train_dataset = NewsDatasets(\n",
    "        # df_train.news.values,df_train.movies.values,df_train.ratings.values\n",
    "        # df_train.news.values,df_valid.title.values, df_valid.category.values, df_valid.abstract.values, df_valid.sub_category.values, df_valid.ratings.values\n",
    "        df_train.news_id.values,df_valid.title.values, df_valid.category.values, df_valid.abstract.values, df_valid.sub_category.values\n",
    "    )\n",
    "    \n",
    "    valid_dataset = NewsDatasets(\n",
    "        # df_train.news.values,df_valid.title.values, df_valid.category.values, df_valid.abstract.values, df_valid.sub_category.values, df_valid.ratings.values\n",
    "        df_train.news_id.values,df_valid.title.values, df_valid.category.values, df_valid.abstract.values, df_valid.sub_category.values\n",
    "\n",
    "    )\n",
    "    model = RecSysModel(num_news = len(lbl_news_id.classes_), \n",
    "                        num_title=len(lbl_title.classes_), \n",
    "                        num_category=len(lbl_category.classes_),\n",
    "                        num_abstract=len(lbl_abstract.classes_),\n",
    "                        num_sub_category=len(lbl_sub_category.classes_)\n",
    "                        )\n",
    "    model.fit(\n",
    "        train_dataset, valid_dataset, train_bs= 1024, valid_bs = 1024, fp16 = True\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "ImportError: cannot import name SystemRandom. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "04ebf1fccd733c983c497b0a0342d21958bfeedfd18a36b387a18420d7b38de9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
